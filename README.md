# ğŸ“ˆ Linear Regression from Scratch with Streamlit

This project demonstrates how to build **Linear Regression** from scratch using only **NumPy**, **Pandas**, and **Matplotlib** â€” without relying on any machine learning libraries like `scikit-learn`. It also features an interactive **Streamlit-based UI**, allowing users to upload their dataset, tweak hyperparameters like **learning rate** and **epochs**, and visually understand how gradient descent affects model learning.

---

## ğŸ¯ Objective

To fit a straight line `y = mx + b` that best approximates the data using **Gradient Descent**, minimizing the prediction error (Mean Squared Error).

---

## ğŸ§  Mathematical Foundations

### 1. Prediction Function

Å· = mx + b


Where:
- `m` = slope (weight)
- `b` = intercept (bias)
- `x` = input feature
- `Å·` = predicted output

---

### 2. Loss Function: Mean Squared Error (MSE)

MSE = (1/n) * Î£ (yáµ¢ - Å·áµ¢)Â²
= (1/n) * Î£ (yáµ¢ - (mxáµ¢ + b))Â²


Where:
- `yáµ¢` = true output
- `Å·áµ¢` = predicted output
- `n` = number of data points

---

### 3. Gradient Descent Optimization

To minimize the loss, we compute gradients:

**Gradient w.r.t. slope `m`:**

âˆ‚MSE/âˆ‚m = (-2/n) * Î£ xáµ¢ * (yáµ¢ - (mxáµ¢ + b))


**Gradient w.r.t. intercept `b`:**

âˆ‚MSE/âˆ‚b = (-2/n) * Î£ (yáµ¢ - (mxáµ¢ + b))


---

### 4. Parameter Update Rules

Using learning rate `Î±`, we iteratively update:

m := m - Î± * âˆ‚MSE/âˆ‚m
b := b - Î± * âˆ‚MSE/âˆ‚b


Repeat for a fixed number of `epochs` or until the change in loss is below a threshold.

---

## ğŸ§¾ Features

- âœ… Linear regression from scratch using NumPy
- âœ… Manual implementation of gradient descent
- âœ… Dynamic control over learning rate and epochs via Streamlit
- âœ… Upload your own datasets with `x` and `y` columns
- âœ… Real-time visualization of regression line and loss curve

---

## ğŸ“¤ Sample CSV Format

Make sure your CSV has exactly two columns named `x` and `y`:

```csv
x,y
1,2
2,4
3,5.9
4,8
5,10
ğŸ“Š Visual Outputs

ğŸ“ Regression Line
Scatter plot of the data
Best-fit line using trained parameters
ğŸ“‰ Loss Curve
Tracks MSE across epochs
Shows how loss decreases with learning
ğŸ–¥ How to Run the App

1. Clone the Repository
git clone https://github.com/yaminiDKS/linear_regression_from_scratch.git
cd linear-regression-from-scratch
2. Create Virtual Environment (Optional but Recommended)
python -m venv venv
source venv/bin/activate      # On Windows: venv\Scripts\activate
3. Install Dependencies
pip install -r requirements.txt
4. Launch the Streamlit App
streamlit run linear_regression_streamlit.py
ğŸ§ª Project Structure

â”œâ”€â”€ linear_regression_streamlit.py     # Main Streamlit app
â”œâ”€â”€ data.csv                           # Sample dataset
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ README.md                          # This file


ğŸ“š Educational Value

This project is ideal for:

Beginners learning ML math
Anyone curious about how gradient descent really works
Students preparing for interviews
Recruiters assessing understanding beyond libraries
ğŸš€ Future Enhancements

 Multivariable linear regression
 Real-time animation of line updates
 Comparison with scikit-learn results
 Downloadable trained parameters
